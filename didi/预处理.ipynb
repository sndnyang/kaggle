{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 滴滴比赛\n",
    "\n",
    "导入必须的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandasql as pql\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文件位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# 训练集数据文件夹\n",
    "base_dir = \"G:/project/dataset/didi/season_1/training_data\"\n",
    "\n",
    "train_cluster_map_file = os.path.join(base_dir, 'cluster_map', 'cluster_map')\n",
    "\n",
    "# 这个 POI 不打算使用\n",
    "train_poi_file = os.path.join(base_dir, 'poi_data', 'poi_data')\n",
    "\n",
    "# 训练集的 gap 中间文件\n",
    "train_sd_gap_file = os.path.join(base_dir, 'sd_gap.csv')\n",
    "\n",
    "# 训练集的 order 中间文件\n",
    "train_order_file = os.path.join(base_dir, 'order_data', 'order_data.csv')\n",
    "\n",
    "train_weather_file = os.path.join(base_dir, 'weather_data', 'weather_data.csv')\n",
    "\n",
    "train_traffic_file = os.path.join(base_dir, 'traffic_data', 'traffic-data.csv')\n",
    "\n",
    "# test data directory\n",
    "test_base_dir = \"G:/project/dataset/didi/season_1/test_set_2\"\n",
    "\n",
    "test_traffic_file = os.path.join(base_dir, 'traffic_data', 'traffic-data.csv')\n",
    "test_order_file = os.path.join(test_base_dir, 'order_data', 'order-data.csv')\n",
    "\n",
    "test_submit_file = os.path.join(test_base_dir, 'test.txt')\n",
    "\n",
    "test_weather_file = os.path.join(test_base_dir, 'weather_data', 'weather_data.csv')\n",
    "\n",
    "# 全部交通数据\n",
    "all_traffic_file = os.path.join(base_dir, '..', 'traffic.csv')\n",
    "\n",
    "sd_gap_file = os.path.join(base_dir, '..', 'gap.csv')\n",
    "\n",
    "weather_file = os.path.join(test_base_dir, '..', 'weather_data.csv')\n",
    "\n",
    "another_weather = os.path.join(test_base_dir, '..', 'weather.txt')\n",
    "full_index_file = os.path.join(base_dir, '..', 'fullindex.csv')\n",
    "\n",
    "full_file = os.path.join(base_dir, '..', 'full_data.csv')\n",
    "\n",
    "# 提交文件\n",
    "submit_file = os.path.join(test_base_dir, '..', 'submit.csv')\n",
    "result_file = os.path.join(test_base_dir, '..', 'result.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 强调中间步骤、 中间文件 **\n",
    "\n",
    "在最终的模型预测之前， 数据预处理、 分析时， 多使用中间文件保存结果\n",
    "\n",
    "避免重复执行步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整DataFrame\n",
    "\n",
    "66个区域 * 21（21+5）天 * 144 个时间片， 再把各项数据并入\n",
    "\n",
    "有完整的， 才知道缺了哪些值， 才能填充—— 我目前想到的办法， 个人觉得比 在原dataframe 上一行行地添加数据来得快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_full_df(day):\n",
    "    \n",
    "    time = range(1, 145)\n",
    "    \n",
    "    regid = np.array([])\n",
    "    dates = np.array([])\n",
    "    times = np.array([])\n",
    "\n",
    "    for d in day:\n",
    "        dates = np.hstack((dates, np.array(['2016-01-%02d' % d] * 66 * 144)))\n",
    "        for i in range(66):\n",
    "            regid = np.hstack((regid, np.array([i+1] * 144)))\n",
    "            times = np.hstack((times, time))\n",
    "\n",
    "    #print len(dates), len(regid), len(times)\n",
    "    full_df = pd.DataFrame({'id': regid, 'Date': dates, 'TimePiece': times}, columns=['id', 'Date', 'TimePiece'])\n",
    "    print len(full_df)\n",
    "    full_index_file = os.path.join(base_dir, '..', 'fullindex2.csv')\n",
    "    full_df.to_csv(full_index_file, index=False)\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256608\n"
     ]
    }
   ],
   "source": [
    "day = range(1, 23) + [23, 25, 27, 29, 30]\n",
    "full_df = generate_full_df(day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从中间文件读取\n",
    "\n",
    "读取中间文件 full_index_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247104\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv(full_index_file, dtype = {'id': np.int16, 'TimePiece': np.int16})\n",
    "print len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        Date  TimePiece\n",
       "0   1  2016-01-01          1\n",
       "1   1  2016-01-01          2\n",
       "2   1  2016-01-01          3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster_map 处理\n",
    "\n",
    "## 区域 hashid 和 实际id\n",
    "\n",
    "cluster_map 数据， pandas 应该比 dict 快， 到时候 merge 或 join 比 从 dict 里找好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(train_cluster_map_file, sep=\"\\t\", header=None, names=['hashid', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashid</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             hashid  id\n",
       "0  90c5a34f06ac86aee0fd70e2adce7d8a   1\n",
       "1  f2c8c4bb99e6377d21de71275afd6cd2   2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 订单 order_data 处理\n",
    "\n",
    "## 复习下 pandas 读数据\n",
    "\n",
    "1. 复习下数据读取, read_csv\n",
    "2. 个人认为不需要的数据， 如 order_id 等id， 该省略的省掉（order_id, passenger_id, dest_district_has）， 该转换的转换, driver_id 变成是否有接单， 时间拆出日期和时间片， start_distrct_hash 改成实际id。 节省空间。去掉一堆 hash的字符串， 可以省很多空间\n",
    "\n",
    "**也许有些信息还有用， 觉得有用时再补充回来**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 时：分：秒 转成 10分钟的时间片\n",
    "def time2Slice(time_str):\n",
    "    l = time_str.split(\":\")\n",
    "    return int(l[0]) * 6 + int(l[1]) / 10 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order data 的数据 hash 太多， 顺便复习下 pandas\n",
    "def reduceOrderFile(base_name, f):\n",
    "    import time\n",
    "    prev = time.time()\n",
    "    fname = os.path.join(base_name, f)\n",
    "    order = pd.read_csv(fname, sep=\"\\t\", header=None, dtype={'Price': np.str},\n",
    "                          names=['order_id', 'driver_id', 'passenger_id', 'start_district_hash', 'dest_district_hash',\n",
    "                                'Price', 'Time'])\n",
    "\n",
    "    full_order = order.merge(cluster_map, left_on='start_district_hash', right_on='hashid')\n",
    "\n",
    "    full_order['Date'] = pd.Series([e.split()[0] for e in full_order['Time']])\n",
    "\n",
    "    full_order['TimePiece'] = pd.Series([time2Slice(e.split()[1]) for e in full_order['Time']])\n",
    "\n",
    "    full_order['Resp'] = full_order['driver_id'].notnull()\n",
    "\n",
    "    small_order = full_order.loc[:, ['Date', 'TimePiece', 'id', 'Price', 'Resp']]\n",
    "    small_order_file = os.path.join(base_name, f + \".csv\")\n",
    "    small_order.to_csv(small_order_file, index = False)\n",
    "    print time.time() - prev\n",
    "    \n",
    "    #return small_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "\n",
    "def testReduceOrder():\n",
    "    z = reduceOrderFile('G:/project/dataset/citydata/season_1/training_data\\order_data', 'order_data_2016-01-21')\n",
    "    print len(z)\n",
    "    print sum(z['Resp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 批量 order reduce\n",
    "def reduceFiles(base_name):\n",
    "    for rt, dirs, files in os.walk(base_name):\n",
    "        for f in files:           \n",
    "            reduceOrderFile(base_name, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.074000120163\n",
      "0.0299999713898\n",
      "0.000999927520752\n",
      "0.0\n",
      "0.0160000324249\n",
      "1.20499992371\n",
      "1.21799993515\n",
      "1.25100016594\n",
      "1.41599988937\n",
      "1.11100006104\n"
     ]
    }
   ],
   "source": [
    "# 运行过就不要再来了， 一个文件6秒， 20个文件， 还是要2分钟的。\n",
    "def runForOnce():\n",
    "    pass\n",
    "reduceFiles(os.path.join(test_base_dir, 'order_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_read_order():\n",
    "    train_order = pd.read_csv(train_order_file, sep=\"\\t\", header=None, dtype={'Price': np.float, 'driver_id': np.str},\n",
    "                          names=['order_id', 'driver_id', 'passenger_id', 'start_district_hash', 'dest_district_hash',\n",
    "                                'Price', 'Time'])\n",
    "    print len(train_order)\n",
    "    t = train_order['driver_id']\n",
    "    print t.notnull()\n",
    "    small_order = full_train_order.loc[:, ['Date', 'TimePiece', 'id', 'Price', 'Resp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取 order 数据\n",
    "\n",
    "训练和测试数据\n",
    "\n",
    "训练数据 训练 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def order2SDGap(filename):\n",
    "    order = pd.read_csv(filename, dtype={'TimePiece': np.int16, 'id': np.int16, 'Price': np.float, 'Resp': np.bool})\n",
    "    \n",
    "    group_all = order.loc[:, ['id', 'Date', 'TimePiece', 'Resp']].groupby(['id', 'Date', 'TimePiece'])\n",
    "    sd_data = group_all.count()\n",
    "    sd_data['supply'] = group_all.Resp.sum()\n",
    "    sd_data['gap'] = sd_data.Resp - sd_data.supply\n",
    "    sd_data.columns = ['demand', 'supply', 'gap']\n",
    "    \n",
    "    sd_df = sd_data.reset_index(level = ['id', 'Date', 'TimePiece'])\n",
    "    sd_df['week'] = pd.Series([datetime.strptime(e, \"%Y-%m-%d\").weekday() for e in sd_df.Date])\n",
    "\n",
    "    return sd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_order = order2SDGap(train_order_file)\n",
    "test_order = order2SDGap(test_order_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成订单的供需缺口中间文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_order.to_csv(train_sd_gap_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>demand</th>\n",
       "      <th>supply</th>\n",
       "      <th>gap</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>191</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        Date  TimePiece  demand  supply  gap  week\n",
       "0   1  2016-01-01          1     187     178    9     4\n",
       "1   1  2016-01-01          2     198     191    7     4\n",
       "2   1  2016-01-01          3     192     182   10     4\n",
       "3   1  2016-01-01          4     172     167    5     4\n",
       "4   1  2016-01-01          5     153     152    1     4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_order[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 从订单供需缺口 中间文件恢复数据\n",
    "\n",
    "对应文件 sd_gap_file,\n",
    "\n",
    "训练集对应文件 train_sd_gap_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sd_df = pd.read_csv(sd_gap_file, dtype = {'id': np.int16, 'TimePiece': np.int16, 'demand': np.int32, \n",
    "                                                'supply': np.int32, 'gap': np.int32, 'week': np.int8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-01-22', '2016-01-24', '2016-01-26', '2016-01-28', '2016-01-30'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = all_sd_df[all_sd_df.Date > '2016-01-21'].loc[:, all_sd_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43,  44,  45,  55,  56,  57,  67,  68,  69,  79,  80,  81,  91,\n",
       "        92,  93, 103, 104, 105, 115, 116, 117, 127, 128, 129, 139, 140, 141], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.TimePiece.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1月3号以后数据比较好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>demand</th>\n",
       "      <th>supply</th>\n",
       "      <th>gap</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        Date  TimePiece  demand  supply  gap  week\n",
       "1008   1  2016-01-08          1      76      72    4     4\n",
       "1009   1  2016-01-08          2      51      50    1     4\n",
       "1010   1  2016-01-08          3      54      53    1     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = all_sd_df[all_sd_df.Date > '2016-01-03']\n",
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>demand</th>\n",
       "      <th>supply</th>\n",
       "      <th>gap</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109059.000000</td>\n",
       "      <td>109059.000000</td>\n",
       "      <td>109059.000000</td>\n",
       "      <td>109059.000000</td>\n",
       "      <td>109059.000000</td>\n",
       "      <td>109059.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.771041</td>\n",
       "      <td>78.345666</td>\n",
       "      <td>54.242905</td>\n",
       "      <td>44.511402</td>\n",
       "      <td>9.731503</td>\n",
       "      <td>3.006969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.573738</td>\n",
       "      <td>39.415784</td>\n",
       "      <td>114.400586</td>\n",
       "      <td>83.286968</td>\n",
       "      <td>46.109139</td>\n",
       "      <td>2.002055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>1341.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id      TimePiece         demand         supply  \\\n",
       "count  109059.000000  109059.000000  109059.000000  109059.000000   \n",
       "mean       31.771041      78.345666      54.242905      44.511402   \n",
       "std        18.573738      39.415784     114.400586      83.286968   \n",
       "min         1.000000       1.000000       1.000000       0.000000   \n",
       "25%        16.000000      49.000000       4.000000       3.000000   \n",
       "50%        31.000000      80.000000      12.000000      10.000000   \n",
       "75%        47.000000     112.000000      48.000000      43.000000   \n",
       "max        66.000000     144.000000    1863.000000     902.000000   \n",
       "\n",
       "                 gap           week  \n",
       "count  109059.000000  109059.000000  \n",
       "mean        9.731503       3.006969  \n",
       "std        46.109139       2.002055  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       1.000000  \n",
       "50%         1.000000       3.000000  \n",
       "75%         4.000000       5.000000  \n",
       "max      1341.000000       6.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交通情况处理\n",
    "\n",
    "## 读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_traffic = pd.read_csv(train_traffic_file, sep=\"\\t\", header=None,\n",
    "                          names=['hashid', 'traffic1', 'traffic2', 'traffic3', 'traffic4', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193553"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交通拥堵情况评估标准\n",
    "\n",
    "1. 四个等级\n",
    "2. t1,..,t4 各自路段数\n",
    "\n",
    "$ value = (t1 * 1 + t2 * 2 + t3 * 3 + t4 * 4) * 0.1 / (t1 * t2 * t3 * t4) $ \n",
    "\n",
    "再用 max, min 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deal_traffic(traffic_file):\n",
    "    traffic_data = pd.read_csv(traffic_file, sep=\"\\t\", header=None,\n",
    "                          names=['hashid', 'traffic1', 'traffic2', 'traffic3', 'traffic4', 'Time'])\n",
    "    traffic_data['Date'] = pd.Series([e.split()[0] for e in traffic_data['Time']])\n",
    "    traffic_data['TimePiece'] = pd.Series([time2Slice(e.split()[1]) for e in traffic_data['Time']])\n",
    "    traffic_data.traffic1 = pd.Series([ int(e.split(':')[1]) for e in traffic_data.traffic1])\n",
    "    traffic_data.traffic2 = pd.Series([ int(e.split(':')[1]) for e in traffic_data.traffic2])\n",
    "    traffic_data.traffic3 = pd.Series([ int(e.split(':')[1]) for e in traffic_data.traffic3])\n",
    "    traffic_data.traffic4 = pd.Series([ int(e.split(':')[1]) for e in traffic_data.traffic4])\n",
    "    \n",
    "    traffic_data['traffic'] = pd.Series((traffic_data.traffic1 + traffic_data.traffic2 * 2 + traffic_data.traffic3 * 3 + traffic_data.traffic4 * 4)\n",
    "                                  * 0.1 /(traffic_data.traffic1 + traffic_data.traffic2 + traffic_data.traffic3 + traffic_data.traffic4) )\n",
    "    traffic_min = traffic_data['traffic'].min()\n",
    "    traffic_max = traffic_data['traffic'].max()\n",
    "\n",
    "    print traffic_max, traffic_min\n",
    "    \n",
    "    traffic_data['traffic'] = (traffic_data['traffic'] - traffic_min) / (traffic_max - traffic_min)\n",
    "    \n",
    "    small_traffic = traffic_data.loc[:, ['hashid', 'Date', 'TimePiece', 'traffic']]\n",
    "    return small_traffic.sort_values(['hashid', 'Date', 'TimePiece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.1\n"
     ]
    }
   ],
   "source": [
    "# all_traffic_file\n",
    "all_traffic = deal_traffic(all_traffic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>201934.000000</td>\n",
       "      <td>201934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.537913</td>\n",
       "      <td>0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.009222</td>\n",
       "      <td>0.043510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.122040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TimePiece        traffic\n",
       "count  201934.000000  201934.000000\n",
       "mean       73.537913       0.094944\n",
       "std        41.009222       0.043510\n",
       "min         2.000000       0.000000\n",
       "25%        39.000000       0.066667\n",
       "50%        74.000000       0.093333\n",
       "75%       109.000000       0.122040\n",
       "max       144.000000       1.000000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traffic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交通情况中间文件\n",
    "\n",
    "对应文件 traffic_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_traffic.to_csv(traffic_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 从交通情况中间文件恢复数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashid</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.127854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.117460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             hashid        Date  TimePiece   traffic\n",
       "0  08232402614a9b48895cc3d0aeb0e9f2  2016-01-01          2  0.075000\n",
       "1  08232402614a9b48895cc3d0aeb0e9f2  2016-01-01          3  0.127854\n",
       "2  08232402614a9b48895cc3d0aeb0e9f2  2016-01-01          4  0.161994\n",
       "3  08232402614a9b48895cc3d0aeb0e9f2  2016-01-01          5  0.117460"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traffic = pd.read_csv(all_traffic_file, dtype={'TimePiece': np.int16})\n",
    "#all_traffic['week'] = pd.Series([datetime.strptime(e, \"%Y-%m-%d\").weekday() for e in all_traffic.Date])\n",
    "#groupWeek = train_traffic.groupby('week')\n",
    "all_traffic[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>201934.000000</td>\n",
       "      <td>201934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.537913</td>\n",
       "      <td>0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.009222</td>\n",
       "      <td>0.043510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.122040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TimePiece        traffic\n",
       "count  201934.000000  201934.000000\n",
       "mean       73.537913       0.094944\n",
       "std        41.009222       0.043510\n",
       "min         2.000000       0.000000\n",
       "25%        39.000000       0.066667\n",
       "50%        74.000000       0.093333\n",
       "75%       109.000000       0.122040\n",
       "max       144.000000       1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traffic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整交通情况填充\n",
    "\n",
    "若干日期 * 66个区域 * 144 个时间片（30-144必需）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.127854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        Date  TimePiece   traffic\n",
       "0  50  2016-01-01          2  0.075000\n",
       "1  50  2016-01-01          3  0.127854\n",
       "2  50  2016-01-01          4  0.161994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_traffic = all_traffic.merge(cluster_map, left_on='hashid', right_on='hashid').loc[:, ['id', 'Date', 'TimePiece', 'traffic']]\n",
    "all_traffic[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201934\n"
     ]
    }
   ],
   "source": [
    "print len(all_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天气数据\n",
    "\n",
    "weather_data.csv 文件\n",
    "\n",
    "another_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3744.000000</td>\n",
       "      <td>3744.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.379274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.573769</td>\n",
       "      <td>1.928555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>108.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TimePiece      Weather\n",
       "count  3744.000000  3744.000000\n",
       "mean     72.500000     2.379274\n",
       "std      41.573769     1.928555\n",
       "min       1.000000     0.000000\n",
       "25%      36.750000     1.000000\n",
       "50%      72.500000     2.000000\n",
       "75%     108.250000     4.000000\n",
       "max     144.000000     9.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.read_csv(another_weather, dtype={'TimePiece': np.int16, 'Weather': np.int8})\n",
    "weather_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-21 143\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "for w, g in weather_df.groupby('Date'):\n",
    "    \n",
    "    if len(g) == 144:\n",
    "        continue\n",
    "    print w, len(g)\n",
    "    t = 0\n",
    "    for ww, gg in g.groupby('TimePiece'):\n",
    "        if ww - t != 1:\n",
    "            print ww\n",
    "        t = ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "247104"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 144*26\n",
    "144*26 * 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整合全体数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247104.00000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>247104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.379274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.05041</td>\n",
       "      <td>41.568301</td>\n",
       "      <td>1.928301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      TimePiece        Weather\n",
       "count  247104.00000  247104.000000  247104.000000\n",
       "mean       33.50000      72.500000       2.379274\n",
       "std        19.05041      41.568301       1.928301\n",
       "min         1.00000       1.000000       0.000000\n",
       "25%        17.00000      36.750000       1.000000\n",
       "50%        33.50000      72.500000       2.000000\n",
       "75%        50.00000     108.250000       4.000000\n",
       "max        66.00000     144.000000       9.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = full_df.merge(weather_df, on=['Date', 'TimePiece'], how='left')\n",
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>Weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        Date  TimePiece  Weather\n",
       "0   1  2016-01-01          1        1\n",
       "1   1  2016-01-01          2        1\n",
       "2   1  2016-01-01          3        1\n",
       "3   1  2016-01-01          4        1\n",
       "4   1  2016-01-01          5        1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n, g in temp_df.groupby('Date'):\n",
    "    \n",
    "    if len(g) == 9504:\n",
    "        continue\n",
    "    print n, len(g)    \n",
    "    for nn, gg in g.groupby('TimePiece'):\n",
    "        if len(gg) == 66:\n",
    "            continue\n",
    "        print nn, len(gg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9504"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "66 * 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>Weather</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247104.00000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>201934.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.379274</td>\n",
       "      <td>0.094944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.05041</td>\n",
       "      <td>41.568301</td>\n",
       "      <td>1.928301</td>\n",
       "      <td>0.043510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.093333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.122040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      TimePiece        Weather        traffic\n",
       "count  247104.00000  247104.000000  247104.000000  201934.000000\n",
       "mean       33.50000      72.500000       2.379274       0.094944\n",
       "std        19.05041      41.568301       1.928301       0.043510\n",
       "min         1.00000       1.000000       0.000000       0.000000\n",
       "25%        17.00000      36.750000       1.000000       0.066667\n",
       "50%        33.50000      72.500000       2.000000       0.093333\n",
       "75%        50.00000     108.250000       4.000000       0.122040\n",
       "max        66.00000     144.000000       9.000000       1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = temp_df.merge(all_traffic, on=['id', 'Date', 'TimePiece'], how='left')\n",
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sd_df.supply.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df = temp_df.merge(all_sd_df, on=['id', 'Date', 'TimePiece'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df['week'] = pd.Series([datetime.strptime(e, \"%Y-%m-%d\").weekday() for e in final_df.Date])\n",
    "final_df['work'] = pd.Series([e < 5 for e in final_df.week])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TimePiece</th>\n",
       "      <th>Weather</th>\n",
       "      <th>traffic</th>\n",
       "      <th>demand</th>\n",
       "      <th>supply</th>\n",
       "      <th>gap</th>\n",
       "      <th>week</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>247104.00000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>201934.000000</td>\n",
       "      <td>171415.000000</td>\n",
       "      <td>171415.000000</td>\n",
       "      <td>171415.000000</td>\n",
       "      <td>247104.000000</td>\n",
       "      <td>247104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.379274</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>53.079363</td>\n",
       "      <td>43.596908</td>\n",
       "      <td>9.482455</td>\n",
       "      <td>3.153846</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.05041</td>\n",
       "      <td>41.568301</td>\n",
       "      <td>1.928301</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>113.876910</td>\n",
       "      <td>82.040953</td>\n",
       "      <td>50.229963</td>\n",
       "      <td>1.974696</td>\n",
       "      <td>0.461539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.50000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>108.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.122040</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.00000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4362.000000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>3872.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id      TimePiece        Weather        traffic  \\\n",
       "count  247104.00000  247104.000000  247104.000000  201934.000000   \n",
       "mean       33.50000      72.500000       2.379274       0.094944   \n",
       "std        19.05041      41.568301       1.928301       0.043510   \n",
       "min         1.00000       1.000000       0.000000       0.000000   \n",
       "25%        17.00000      36.750000       1.000000       0.066667   \n",
       "50%        33.50000      72.500000       2.000000       0.093333   \n",
       "75%        50.00000     108.250000       4.000000       0.122040   \n",
       "max        66.00000     144.000000       9.000000       1.000000   \n",
       "\n",
       "              demand         supply            gap           week      work  \n",
       "count  171415.000000  171415.000000  171415.000000  247104.000000    247104  \n",
       "mean       53.079363      43.596908       9.482455       3.153846  0.692308  \n",
       "std       113.876910      82.040953      50.229963       1.974696  0.461539  \n",
       "min         1.000000       0.000000       0.000000       0.000000     False  \n",
       "25%         4.000000       3.000000       0.000000       1.000000         0  \n",
       "50%        12.000000      10.000000       1.000000       3.000000         1  \n",
       "75%        48.000000      42.000000       4.000000       5.000000         1  \n",
       "max      4362.000000    1084.000000    3872.000000       6.000000      True  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id int16\n",
      "Date object\n",
      "TimePiece int16\n",
      "week int64\n",
      "work bool\n",
      "Weather int8\n",
      "demand float64\n",
      "supply float64\n",
      "gap float64\n",
      "traffic float64\n"
     ]
    }
   ],
   "source": [
    "for c in final_df.columns:\n",
    "    print c, final_df[c].dtype\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = final_df.loc[:, ['id', 'Date', 'TimePiece', 'week', 'work', 'Weather', 'demand', 'supply', 'gap', 'traffic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv(full_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
